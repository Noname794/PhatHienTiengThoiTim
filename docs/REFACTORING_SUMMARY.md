# Refactoring Summary - CNN Notebook

## âœ… ÄÃ£ HoÃ n ThÃ nh

File `04_training_cnn_method1.ipynb` Ä‘Ã£ Ä‘Æ°á»£c refactor Ä‘á»ƒ sá»­ dá»¥ng `data_preprocessing.py` module.

---

## ğŸ“ Nhá»¯ng Thay Äá»•i

### 1. **Cell 1 - Import**
**TrÆ°á»›c:**
```python
import librosa
from tqdm.notebook import tqdm
from scipy.signal import butter, filtfilt
from kymatio.numpy import Scattering1D
# ... nhiá»u imports khÃ¡c
```

**Sau:**
```python
# Import preprocessing module
sys.path.append('../src')
from data_preprocessing import HeartSoundPreprocessor
# ... chá»‰ giá»¯ láº¡i imports cáº§n thiáº¿t cho model
```

**Lá»£i Ã­ch:** Giáº£m dependencies, code sáº¡ch hÆ¡n

---

### 2. **Cell 4-5 - Loáº¡i bá» Helper Functions**
**TrÆ°á»›c:**
```python
def butter_lowpass_filter(data, cutoff, sr, order=5):
    # ... 30+ lines code
    
def normalize_signal(sig):
    # ... code
    
def extract_cycles(wav_path, tsv_path):
    # ... 40+ lines code
    
def extract_scattering_features(signal, scattering):
    # ... code
```

**Sau:**
```python
# Khá»Ÿi táº¡o preprocessor
preprocessor = HeartSoundPreprocessor(
    sr=SR,
    max_len=MAX_LEN,
    cutoff_freq=CUTOFF_FREQ,
    scattering_j=J
)
```

**Lá»£i Ã­ch:** Loáº¡i bá» ~100 lines duplicate code

---

### 3. **Cell 8-9 - Load Labels & Process Data**
**TrÆ°á»›c:**
```python
# Äá»c metadata
df_info = pd.read_csv(METADATA_FILE)
df_info.columns = [col.replace(' ', '_') for col in df_info.columns]

label_dict = {}
for _, row in df_info.iterrows():
    # ... 10+ lines code
    
# Khá»Ÿi táº¡o Scattering Transform
scattering = Scattering1D(J=J, shape=MAX_LEN)

X = []
y = []

for fname in tqdm(wav_files, desc="Processing"):
    # ... 30+ lines code
    cycles = extract_cycles(wav_path, tsv_path)
    for cycle in cycles:
        features = extract_scattering_features(cycle, scattering)
        X.append(features)
        y.append(label)
```

**Sau:**
```python
# Xá»­ lÃ½ dataset báº±ng preprocessing module
X, y = preprocessor.process_dataset(
    raw_data_dir=RAW_DATA_DIR,
    metadata_file=METADATA_FILE,
    use_scattering=True,
    verbose=True
)
```

**Lá»£i Ã­ch:** Tá»« ~50 lines â†’ 6 lines

---

### 4. **Cell 12-13 - Balance Dataset**
**TrÆ°á»›c:**
```python
# Filter indices by label
idx_present = np.where(y == 1)[0]
idx_absent = np.where(y == 0)[0]

n_present = len(idx_present)

np.random.seed(42)
idx_absent_reduced = np.random.choice(idx_absent, size=n_present, replace=False)

idx_final = np.concatenate([idx_present, idx_absent_reduced])
idx_final = shuffle(idx_final, random_state=42)

X_balanced = X[idx_final]
y_balanced = y[idx_final]
```

**Sau:**
```python
# Balance dataset báº±ng preprocessing module
X_balanced, y_balanced = preprocessor.balance_dataset(X, y, random_state=42)
```

**Lá»£i Ã­ch:** Tá»« ~12 lines â†’ 1 line

---

### 5. **Bonus - Save/Load Data (Optional)**
**ThÃªm má»›i:**
```python
# (Optional) LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
preprocessor.save_processed_data(X_balanced, y_balanced, PROCESSED_DATA_DIR)

# (Optional) Load dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
X_balanced, y_balanced = preprocessor.load_processed_data(PROCESSED_DATA_DIR)
```

**Lá»£i Ã­ch:** CÃ³ thá»ƒ skip preprocessing khi cháº¡y láº¡i

---

## ğŸ“Š Káº¿t Quáº£

### Code Reduction
| Metric | TrÆ°á»›c | Sau | Giáº£m |
|--------|-------|-----|------|
| **Total cells** | 24 | 22 | -2 |
| **Preprocessing code** | ~150 lines | ~10 lines | **-93%** |
| **Dependencies** | 15+ imports | 8 imports | -47% |

### Maintainability
- âœ… **DRY Principle**: KhÃ´ng duplicate code giá»¯a CNN vÃ  LSTM notebooks
- âœ… **Single Source of Truth**: Preprocessing logic chá»‰ á»Ÿ 1 nÆ¡i
- âœ… **Easier Updates**: Sá»­a preprocessing â†’ tá»± Ä‘á»™ng apply cho cáº£ 2 models
- âœ… **Reusability**: Dá»… dÃ ng táº¡o models má»›i

---

## ğŸ¯ Cáº¥u TrÃºc Má»›i

```
VIP/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_preprocessing.py          # â­ Single source of truth
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 04_training_cnn_method1.ipynb  # âœ… Refactored - uses module
â”‚   â””â”€â”€ 05_training_lstm_method.ipynb  # âœ… Already uses module
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ processed_cnn_method/          # CÃ³ thá»ƒ save/load
    â””â”€â”€ processed_lstm_method/
```

---

## ğŸš€ Workflow Má»›i

### Láº§n Ä‘áº§u cháº¡y:
```python
# 1. Khá»Ÿi táº¡o preprocessor
preprocessor = HeartSoundPreprocessor(sr=4000, max_len=3000, ...)

# 2. Process data
X, y = preprocessor.process_dataset(raw_data_dir, metadata_file)

# 3. Balance
X_balanced, y_balanced = preprocessor.balance_dataset(X, y)

# 4. (Optional) Save Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
preprocessor.save_processed_data(X_balanced, y_balanced, output_dir)

# 5. Train model
# ...
```

### Láº§n sau cháº¡y (nhanh hÆ¡n):
```python
# 1. Khá»Ÿi táº¡o preprocessor
preprocessor = HeartSoundPreprocessor(sr=4000, max_len=3000, ...)

# 2. Load data Ä‘Ã£ xá»­ lÃ½
X_balanced, y_balanced = preprocessor.load_processed_data(output_dir)

# 3. Train model ngay
# ...
```

---

## âœ¨ Lá»£i Ãch ChÃ­nh

### 1. **Code Quality**
- Giáº£m 93% preprocessing code trong notebook
- Dá»… Ä‘á»c, dá»… hiá»ƒu hÆ¡n
- Follow best practices (separation of concerns)

### 2. **Maintainability**
- Sá»­a bug á»Ÿ 1 nÆ¡i â†’ apply cho táº¥t cáº£
- Dá»… thÃªm features má»›i
- Dá»… test preprocessing logic riÃªng

### 3. **Reusability**
- DÃ¹ng cho CNN, LSTM, GRU, ...
- DÃ¹ng cho cÃ¡c experiments khÃ¡c
- DÃ¹ng cho production code

### 4. **Performance**
- CÃ³ thá»ƒ save/load processed data
- KhÃ´ng cáº§n reprocess má»—i láº§n cháº¡y
- Tiáº¿t kiá»‡m thá»i gian development

---

## ğŸ”„ Migration Guide

Náº¿u báº¡n cÃ³ notebooks khÃ¡c muá»‘n refactor:

### BÆ°á»›c 1: Import module
```python
import sys
sys.path.append('../src')
from data_preprocessing import HeartSoundPreprocessor
```

### BÆ°á»›c 2: Thay tháº¿ preprocessing code
```python
# Thay vÃ¬:
# - butter_lowpass_filter()
# - normalize_signal()
# - extract_cycles()
# - extract_scattering_features()
# - load_labels()
# - balance dataset code

# DÃ¹ng:
preprocessor = HeartSoundPreprocessor(...)
X, y = preprocessor.process_dataset(...)
X_balanced, y_balanced = preprocessor.balance_dataset(X, y)
```

### BÆ°á»›c 3: Giá»¯ nguyÃªn model code
```python
# Model architecture vÃ  training code khÃ´ng Ä‘á»•i
model = build_model(...)
model.fit(X_train, y_train, ...)
```

---

## ğŸ“š Files LiÃªn Quan

1. **`src/data_preprocessing.py`** - Preprocessing module
2. **`notebooks/04_training_cnn_method1.ipynb`** - CNN notebook (refactored)
3. **`notebooks/05_training_lstm_method.ipynb`** - LSTM notebook (already clean)
4. **`docs/PREPROCESSING_AND_MODELS.md`** - Full documentation

---

## âœ… Checklist

- [x] Refactor CNN notebook
- [x] Test preprocessing module
- [x] Add save/load functionality
- [x] Update documentation
- [x] Verify both notebooks work with module

---

## ğŸ‰ Káº¿t Luáº­n

File `04_training_cnn_method1.ipynb` giá» Ä‘Ã¢y:
- âœ… **Sáº¡ch hÆ¡n**: Giáº£m 93% preprocessing code
- âœ… **Dá»… maintain**: Single source of truth
- âœ… **Consistent**: CÃ¹ng preprocessing vá»›i LSTM notebook
- âœ… **Professional**: Follow software engineering best practices

**Báº¡n cÃ³ thá»ƒ XÃ“A file `example_using_preprocessor.ipynb`** vÃ¬ cáº£ 2 notebooks chÃ­nh Ä‘Ã£ sá»­ dá»¥ng module rá»“i! ğŸ—‘ï¸
